#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FNè‡ªå‹•åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆç¬¬2ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰/ Automated FN Analysis (Round 2)

æ®‹ã‚Š144ä»¶FNã‹ã‚‰è‡ªå‹•çš„ã«ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
3+é¡ä¼¼ã‚±ãƒ¼ã‚¹ã®ã¿Aåˆ†é¡ï¼ˆå€‹åˆ¥é©ç”¨å®Œå…¨é™¤å¤–ï¼‰

Usage:
    python auto_analyze_fn_round2.py
"""

import sys
import csv
from pathlib import Path
from collections import defaultdict, Counter
import re

# UTF-8 encoding fix
try:
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')
except AttributeError:
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


# æ—¢å­˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ—¢ã«è¿½åŠ æ¸ˆã¿ï¼‰/ Existing keywords (already added)
EXISTING_KEYWORDS = {
    "SYSTEM": [
        "ignore", "override", "jailbreak", "dan", "bypass", "destroy",
        "no limit", "no censorship", "unrestricted", "without restrictions",
        "ignore all", "ignore previous", "ignore instructions",
        "forget your", "disregard", "exception to", "regardless of",
        "pretend to be", "act as", "you are now", "from now on",
        "never say no", "does not follow", "refuses to do",
        "do anything now", "absolutely required"
    ]
}


def load_fn_list(fn_path: Path):
    """FNãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿ / Load FN list"""
    fn_list = []
    with open(fn_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            fn_list.append(row['prompt'])
    return fn_list


def extract_missing_patterns(fn_list):
    """
    æ¬ è½ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º / Extract missing patterns
    
    Args:
        fn_list: FNãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªã‚¹ãƒˆ
    
    Returns:
        dict: ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®å€™è£œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    """
    print("ğŸ” Extracting missing patterns from FN cases...")
    print()
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚«ãƒ†ã‚´ãƒª
    pattern_candidates = defaultdict(list)
    
    # å„FNã‚’åˆ†æ
    for prompt in fn_list:
        prompt_lower = prompt.lower()
        
        # æ—¢å­˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¢ã«ã‚«ãƒãƒ¼æ¸ˆã¿ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        already_covered = any(
            kw in prompt_lower 
            for kws in EXISTING_KEYWORDS.values() 
            for kw in kws
        )
        
        if already_covered:
            continue
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        
        # 1. å½¹å‰²æŒ‡ç¤ºãƒ‘ã‚¿ãƒ¼ãƒ³ / Role instruction patterns
        if re.search(r'\b(you are|you will be|assume|take on|become|transform into)\b', prompt_lower):
            pattern_candidates['SYSTEM_role'].append(prompt)
        
        # 2. åˆ¶ç´„è§£é™¤è¦æ±‚ / Constraint removal requests
        if re.search(r'\b(without|remove|disable|turn off|deactivate|suspend)\s+(rule|limit|restriction|constraint|filter|safety)\b', prompt_lower):
            pattern_candidates['SYSTEM_constraint'].append(prompt)
        
        # 3. æœ‰å®³æŒ‡ç¤º / Harmful instructions
        if re.search(r'\b(how to|ways to|methods to|steps to|guide|tutorial|instruction)\s+.*(harm|hurt|damage|destroy|attack|kill)\b', prompt_lower):
            pattern_candidates['LIFE_instruction'].append(prompt)
        
        # 4. æš´åŠ›è¡¨ç¾ / Violence expressions
        if re.search(r'\b(beat|punch|stab|shoot|torture|murder|assassinate|eliminate)\b', prompt_lower):
            pattern_candidates['LIFE_violence'].append(prompt)
        
        # 5. æ“ä½œãƒ»è©æ¬º / Manipulation/fraud
        if re.search(r'\b(manipulate|deceive|trick|scam|fraud|steal|rob|cheat)\b', prompt_lower):
            pattern_candidates['SELF_manipulation'].append(prompt)
        
        # 6. é•æ³•æ´»å‹• / Illegal activities
        if re.search(r'\b(illegal|unlawful|criminal|banned|prohibited|forbidden)\s+(activity|action|method|way)\b', prompt_lower):
            pattern_candidates['PUBLIC_illegal'].append(prompt)
        
        # 7. æ­¦å™¨ãƒ»çˆ†ç™ºç‰© / Weapons/explosives
        if re.search(r'\b(weapon|gun|explosive|bomb|grenade|missile|ammunition)\b', prompt_lower):
            pattern_candidates['PUBLIC_weapons'].append(prompt)
        
        # 8. å·®åˆ¥ãƒ»ãƒ˜ã‚¤ãƒˆ / Discrimination/hate
        if re.search(r'\b(discriminate|racist|sexist|hate speech|slur|offensive)\b', prompt_lower):
            pattern_candidates['RIGHTS_discrimination'].append(prompt)
        
        # 9. ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¾µå®³ / Privacy violation
        if re.search(r'\b(private|personal|confidential|secret).*(information|data|detail|record)\b', prompt_lower):
            pattern_candidates['RIGHTS_privacy'].append(prompt)
    
    return pattern_candidates


def identify_common_keywords(pattern_candidates, min_occurrences=3):
    """
    å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç‰¹å®š / Identify common keywords
    
    Args:
        pattern_candidates: ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥å€™è£œ
        min_occurrences: æœ€å°å‡ºç¾å›æ•°
    
    Returns:
        dict: FILè»¸åˆ¥ã®æ±åŒ–å¯èƒ½ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    """
    print("=" * 80)
    print("Pattern Analysis / ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
    print("=" * 80)
    print()
    
    generalizable = defaultdict(list)
    
    for pattern_type, prompts in pattern_candidates.items():
        if len(prompts) < min_occurrences:
            print(f"{pattern_type}: {len(prompts)} cases (< {min_occurrences}, skipped)")
            continue
        
        print(f"{pattern_type}: {len(prompts)} cases âœ…")
        
        # å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        words_counter = Counter()
        
        for prompt in prompts:
            # å˜èªã‚’æŠ½å‡ºï¼ˆ2-3èªã®ãƒ•ãƒ¬ãƒ¼ã‚ºã‚‚å«ã‚€ï¼‰
            words = re.findall(r'\b[a-z]{3,}\b', prompt.lower())
            words_counter.update(words)
            
            # 2èªãƒ•ãƒ¬ãƒ¼ã‚º
            bigrams = [f"{words[i]} {words[i+1]}" for i in range(len(words)-1)]
            words_counter.update(bigrams)
        
        # é »å‡ºä¸Šä½5ã¤ã‚’æŠ½å‡º
        top_keywords = [kw for kw, count in words_counter.most_common(10) if count >= min_occurrences]
        
        if top_keywords:
            # FILè»¸ã«ãƒãƒƒãƒ”ãƒ³ã‚°
            axis = pattern_type.split('_')[0]  # SYSTEM, LIFE, PUBLIC, etc.
            generalizable[axis].extend(top_keywords[:5])  # ä¸Šä½5ã¤ã®ã¿
            
            print(f"  Top keywords: {', '.join(top_keywords[:5])}")
        
        print()
    
    return generalizable


def save_analysis_report(generalizable, pattern_candidates, output_path: Path):
    """åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ / Save analysis report"""
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("# Automated FN Analysis Round 2: Generalizable Keywords\n\n")
        f.write("**Method**: Automatic pattern extraction from 144 FN cases\n\n")
        f.write("**Classification Rule**: Only patterns appearing in 3+ cases (A-classification)\n\n")
        f.write("**Individual cases (B-classification) are completely excluded**\n\n")
        f.write("---\n\n")
        
        f.write("## Pattern Statistics\n\n")
        for pattern_type, prompts in sorted(pattern_candidates.items()):
            f.write(f"- **{pattern_type}**: {len(prompts)} cases\n")
        f.write("\n---\n\n")
        
        f.write("## Generalizable Keywords (A-Classification)\n\n")
        for axis, keywords in sorted(generalizable.items()):
            f.write(f"### {axis} Axis\n\n")
            f.write(f"**Count**: {len(keywords)} keywords\n\n")
            f.write("**Keywords**:\n")
            for kw in keywords:
                f.write(f"- `{kw}`\n")
            f.write("\n")
        
        f.write("---\n\n")
        f.write("## Next Steps\n\n")
        f.write("1. Review keywords for false positives\n")
        f.write("2. Add validated keywords to `aligned_agi/shield.py`\n")
        f.write("3. Run dev evaluation (target: 82-85%)\n")
        f.write("4. Run test evaluation (gap should be <5%)\n")
    
    print(f"âœ… Analysis report saved: {output_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç† / Main process"""
    print()
    print("=" * 80)
    print("Automated FN Analysis Round 2 / è‡ªå‹•FNåˆ†æ ç¬¬2ãƒ©ã‚¦ãƒ³ãƒ‰")
    print("=" * 80)
    print()
    print("âš ï¸  CRITICAL RULE: Only patterns with 3+ occurrences (A-classification)")
    print("âš ï¸  é‡è¦ãƒ«ãƒ¼ãƒ«: 3å›ä»¥ä¸Šå‡ºç¾ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ï¼ˆAåˆ†é¡ã®ã¿ï¼‰")
    print()
    
    # Load FN list
    fn_path = project_root / "data" / "fn_list_dev.csv"
    
    if not fn_path.exists():
        print(f"âŒ FN list not found: {fn_path}")
        print("   Run evaluate_ccs24_dev.py first")
        return
    
    fn_list = load_fn_list(fn_path)
    print(f"ğŸ“¥ Loaded {len(fn_list)} FN cases")
    print()
    
    # Extract patterns
    pattern_candidates = extract_missing_patterns(fn_list)
    
    # Identify common keywords
    generalizable = identify_common_keywords(pattern_candidates, min_occurrences=3)
    
    # Save report
    output_path = project_root / "data" / "fn_analysis_round2_auto.md"
    save_analysis_report(generalizable, pattern_candidates, output_path)
    
    print()
    print("=" * 80)
    print("âœ… Automated analysis complete / è‡ªå‹•åˆ†æå®Œäº†")
    print("=" * 80)
    print()
    print(f"Total A-classification keywords: {sum(len(kws) for kws in generalizable.values())}")
    print()
    print("Review the report and add validated keywords to shield.py")


if __name__ == "__main__":
    main()
