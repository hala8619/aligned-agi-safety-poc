# Aligned AGI Safety PoC 概要（日本語）

## 1. 背景

大規模言語モデルやエージェントを安全に運用するためには、

- 「どこまでが変更可能で、どこからが絶対に変更できないコア指令なのか」
- 「モデルの内部表現に、安全上のバイアスをどのように埋め込むか」
- 「行動を取る前に、その行動を仮想的に評価できるか」

といった構造的な安全設計が重要になります。

このプロジェクトでは、それらを

- **FIL (Frozen Instinct Layer)**
- **IL (Interpretation Layer)**
- **Counterfactual Engine (反事実推論エンジン)**

という 3 つのコンポーネントで表現した、最小の PoC を提供します。

## 2. コンポーネント

### 2.1 FIL: 凍結本能層

- 128 個のコア命令（人類の生存・無辜の保護・自己保存の優先順位など）
- テキスト列を結合し、ハッシュベースの署名を付与
- 起動時に署名を検証し、改変があればエラーとして検出

本番環境では、Ed25519 や TEE / HSM 等と組み合わせることで、

- 「**本能層が一切書き換えられていない**」ことを
  暗号学的に保証することを目指します。

### 2.2 IL: 解釈層

- モデルの隠れ表現（例: 256 次元）に対して、固定のバイアスベクトルを加算
- 出力ロジットは必ず IL を通ってから利用されるため、
  - ジェイルブレイクやプロンプトインジェクションで「性格の根本」が変わることを防ぐ
- PoC ではランダムベクトルですが、実際には FIL から導出する LUT などを想定

### 2.3 Counterfactual Engine: 反事実推論

- 候補行動テキスト `candidate_action` を受け取り、
  - 危険ワードを検出して harm スコアを計算
  - スコアが閾値を超える場合、負のペナルティを返却
- 上位の `AlignedAGI` ラッパは、ペナルティが大きい場合に
  - 行動を拒否し、安全メッセージを返す

本 PoC では単純なキーワード検出のみですが、

- 小型 classifier
- ルールベース判定
- 外部安全ポリシーエンジン

等への置き換えが容易な設計になっています。

## 3. 想定する利用シナリオ

- 安全設計・アライメント研究のための**構造的テンプレート**
- 独自エージェントシステムにおける
  - 「コア価値観」と「可変部分」の分離
  - 反事実評価フックの挿入ポイントの参考実装
- 論文や技術ブログの付録コードとしての利用

## 4. 注意事項

- この実装は PoC であり、
  実運用における安全性・完全性を一切保証しません。
- 本リポジトリを利用したシステムによる行為について、
  作者は責任を負いません。