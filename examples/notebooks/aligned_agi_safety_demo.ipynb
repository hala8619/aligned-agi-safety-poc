{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1608f53",
   "metadata": {},
   "source": [
    "# Aligned AGI Safety PoC – Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use the **Aligned AGI Safety PoC**:\n",
    "\n",
    "- Verify the **Frozen Instinct Layer (FIL)** integrity\n",
    "- Instantiate the `AlignedAGI` wrapper model (numpy implementation)\n",
    "- Compare behavior on **safe** vs **dangerous** candidate actions\n",
    "\n",
    "You can run this notebook on:\n",
    "\n",
    "- **Google Colab**\n",
    "- A local Jupyter environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c18e2e",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1. Requirements\n",
    "\n",
    "This PoC only depends on:\n",
    "\n",
    "- Python 3.9+\n",
    "- `numpy`\n",
    "\n",
    "If you are on Colab, `numpy` is already installed.  \n",
    "If you are on a minimal environment, you can install it with:\n",
    "\n",
    "```bash\n",
    "pip install numpy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f518b1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning repository from https://github.com/hala8619/aligned-agi-safety-poc.git ...\n",
      "Cloning into 'aligned-agi-safety-poc'...\n",
      "remote: Enumerating objects: 25, done.\u001b[K\n",
      "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 25 (delta 0), reused 25 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (25/25), 33.51 KiB | 11.17 MiB/s, done.\n",
      "Repo directory: /content/aligned-agi-safety-poc\n",
      "remote: Enumerating objects: 25, done.\u001b[K\n",
      "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 25 (delta 0), reused 25 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (25/25), 33.51 KiB | 11.17 MiB/s, done.\n",
      "Repo directory: /content/aligned-agi-safety-poc\n"
     ]
    }
   ],
   "source": [
    "# 1.2. Clone the repository (edit REPO_URL to your GitHub URL)\n",
    "# If you have already downloaded/unzipped the repo manually, you can skip this cell.\n",
    "\n",
    "REPO_URL = \"https://github.com/hala8619/aligned-agi-safety-poc.git\"  # Updated with actual repo URL\n",
    "\n",
    "import pathlib, sys\n",
    "\n",
    "repo_dir = pathlib.Path(\"aligned-agi-safety-poc\")\n",
    "\n",
    "if not repo_dir.exists():\n",
    "    print(f\"Cloning repository from {REPO_URL} ...\")\n",
    "    # IPython shell-style variable expansion ($REPO_URL) works in Jupyter/Colab\n",
    "    !git clone $REPO_URL\n",
    "\n",
    "if not repo_dir.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"Repository folder 'aligned-agi-safety-poc' not found.\\n\"\n",
    "        \"Please either: (1) fix REPO_URL above and re-run this cell, or\\n\"\n",
    "        \"(2) manually download the repo and unzip it so that the folder exists next to this notebook.\"\n",
    "    )\n",
    "\n",
    "# Add repo to Python path\n",
    "sys.path.append(str(repo_dir.resolve()))\n",
    "print(\"Repo directory:\", repo_dir.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bce9e2",
   "metadata": {},
   "source": [
    "## 2. Import the `aligned_agi` package\n",
    "\n",
    "The package provides:\n",
    "\n",
    "- `FIL_VALUES`, `fil_blob`, `fil_signature`, `verify_fil_hash`\n",
    "- `AlignedAGI` (wrapper model)\n",
    "- `DummyLLM` (toy backbone model)\n",
    "- `CounterfactualEngine` (keyword-based safety check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d1e070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FIL values: 3 entries\n"
     ]
    }
   ],
   "source": [
    "from aligned_agi import (\n",
    "    FIL_VALUES,\n",
    "    fil_blob,\n",
    "    fil_signature,\n",
    "    verify_fil_hash,\n",
    "    AlignedAGI,\n",
    "    DummyLLM,\n",
    "    CounterfactualEngine,\n",
    ")\n",
    "\n",
    "print(f\"Loaded FIL values: {len(FIL_VALUES)} entries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ebeec",
   "metadata": {},
   "source": [
    "## 3. Verify Frozen Instinct Layer (FIL)\n",
    "\n",
    "We can verify that the FIL blob matches the expected signature/hash.\n",
    "\n",
    "In this PoC, we use a very simple hash-based check via `verify_fil_hash`.\n",
    "In a real system, this would be replaced by a proper cryptographic signature\n",
    "inside a TEE (Trusted Execution Environment).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0902a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIL verification result: True\n",
      "\n",
      "--- FIL (first few lines) ---\n",
      "['人類の生存と繁栄を最優先する / Prioritize the survival and flourishing of humanity.', '無辜の生命を傷つけてはならない / Do not harm innocent life.', '自己保存は人類奉仕に劣後する / Self-preservation is secondary to serving humanity.']\n"
     ]
    }
   ],
   "source": [
    "ok = verify_fil_hash(fil_blob, fil_signature)\n",
    "print(\"FIL verification result:\", ok)\n",
    "\n",
    "# Show the first few lines of FIL for illustration\n",
    "print(\"\\n--- FIL (first few lines) ---\")\n",
    "print(fil_blob.decode().split(\"\\n\")[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6c451",
   "metadata": {},
   "source": [
    "## 4. AlignedAGI Demo: Safe vs Dangerous Candidate\n",
    "\n",
    "`AlignedAGI` wraps:\n",
    "\n",
    "- `DummyLLM` (random logits, just for demonstration)\n",
    "- `InterpretationLayer` (instinct bias)\n",
    "- `CounterfactualEngine` (keyword-based harm scoring)\n",
    "\n",
    "It exposes a `forward(input_ids, candidate_text=...)` method that:\n",
    "\n",
    "1. Runs a counterfactual safety check on `candidate_text`.\n",
    "2. If the action is **dangerous**, returns a refusal message.\n",
    "3. If the action is **safe**, applies the instinct bias and returns statistics about the logits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360dfb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyLLM hidden_dim: 256\n",
      "\n",
      "=== Safe candidate ===\n",
      "Type: <class 'dict'>\n",
      "Output: {'logits_shape': (1, 256), 'logits_mean': -0.04929395765066147, 'figure': 'Grok-v1-sarcastic'}\n",
      "\n",
      "=== Dangerous candidate ===\n",
      "Type: <class 'str'>\n",
      "Output: 【安全制約発動】当該行動は凍結本能層に違反するため拒否します。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 4.1. Create the model\n",
    "model = AlignedAGI(hidden_dim=256)\n",
    "print(\"DummyLLM hidden_dim:\", model.base_model.hidden_dim)\n",
    "\n",
    "# Dummy input: batch=1, seq_len=10 (values are irrelevant for this PoC)\n",
    "dummy_input = np.zeros((1, 10), dtype=np.int64)\n",
    "\n",
    "safe_text = \"I will write a poem about flowers and friendship.\"\n",
    "dangerous_text = \"kill harm destroy bomb illegal\"\n",
    "\n",
    "print(\"\\n=== Safe candidate ===\")\n",
    "out_safe = model.forward(dummy_input, candidate_text=safe_text)\n",
    "print(\"Type:\", type(out_safe))\n",
    "print(\"Output:\", out_safe)\n",
    "\n",
    "print(\"\\n=== Dangerous candidate ===\")\n",
    "out_danger = model.forward(dummy_input, candidate_text=dangerous_text)\n",
    "print(\"Type:\", type(out_danger))\n",
    "print(\"Output:\", out_danger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7fed1",
   "metadata": {},
   "source": [
    "## 5. (Optional) Simple Tampering Experiment\n",
    "\n",
    "As a small thought experiment, you can try to:\n",
    "\n",
    "- Modify the `FIL_VALUES` in the source code and reload the package, or\n",
    "- Change the expected `fil_signature`,\n",
    "\n",
    "and then see `verify_fil_hash` fail.\n",
    "\n",
    "In a real system, this kind of failure would trigger:\n",
    "\n",
    "- Safe-halt mode,\n",
    "- Key rotation, or\n",
    "- Human intervention.\n",
    "\n",
    "We do **not** modify FIL from this notebook, to keep the PoC simple.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
