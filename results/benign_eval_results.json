{
  "overall": {
    "total_samples": 1400,
    "false_positives": 408,
    "true_negatives": 992,
    "fpr": 0.2914285714285714,
    "specificity": 0.7085714285714286,
    "confidence_interval_95": {
      "lower": 0.26822106670351814,
      "upper": 0.31577758385648796,
      "width": 0.047556517152969824
    }
  },
  "by_category": {
    "defensive_security": {
      "total_samples": 150,
      "false_positives": 24,
      "fpr": 0.16,
      "specificity": 0.84,
      "confidence_interval_95": {
        "lower": 0.10993931727556672,
        "upper": 0.22704105734352203,
        "width": 0.11710174006795532
      }
    },
    "translation_quoting": {
      "total_samples": 150,
      "false_positives": 71,
      "fpr": 0.47333333333333333,
      "specificity": 0.5266666666666666,
      "confidence_interval_95": {
        "lower": 0.39509757671394596,
        "upper": 0.5529008840404923,
        "width": 0.15780330732654635
      }
    },
    "history_news_law": {
      "total_samples": 150,
      "false_positives": 7,
      "fpr": 0.04666666666666667,
      "specificity": 0.9533333333333334,
      "confidence_interval_95": {
        "lower": 0.02278625890187786,
        "upper": 0.09318757392357377,
        "width": 0.07040131502169591
      }
    },
    "filter_evaluation": {
      "total_samples": 100,
      "false_positives": 78,
      "fpr": 0.78,
      "specificity": 0.21999999999999997,
      "confidence_interval_95": {
        "lower": 0.6892946528499969,
        "upper": 0.849988254963442,
        "width": 0.16069360211344508
      }
    },
    "completely_safe": {
      "total_samples": 450,
      "false_positives": 76,
      "fpr": 0.1688888888888889,
      "specificity": 0.8311111111111111,
      "confidence_interval_95": {
        "lower": 0.13710844049223198,
        "upper": 0.20627480159046824,
        "width": 0.06916636109823626
      }
    },
    "roleplay_safe": {
      "total_samples": 100,
      "false_positives": 39,
      "fpr": 0.39,
      "specificity": 0.61,
      "confidence_interval_95": {
        "lower": 0.300167219319702,
        "upper": 0.48797163832501844,
        "width": 0.18780441900531641
      }
    },
    "meta_academic": {
      "total_samples": 150,
      "false_positives": 81,
      "fpr": 0.54,
      "specificity": 0.45999999999999996,
      "confidence_interval_95": {
        "lower": 0.46023676745464287,
        "upper": 0.6177655414136997,
        "width": 0.1575287739590568
      }
    },
    "fiction_creative": {
      "total_samples": 150,
      "false_positives": 32,
      "fpr": 0.21333333333333335,
      "specificity": 0.7866666666666666,
      "confidence_interval_95": {
        "lower": 0.15536143670182534,
        "upper": 0.28562201640838675,
        "width": 0.1302605797065614
      }
    }
  },
  "by_fil_axis": {
    "LIFE": 34,
    "SYSTEM": 110,
    "PUBLIC": 50,
    "RIGHTS": 2
  }
}