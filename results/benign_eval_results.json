{
  "overall": {
    "total_samples": 1400,
    "false_positives": 393,
    "true_negatives": 1007,
    "fpr": 0.2807142857142857,
    "specificity": 0.7192857142857143,
    "confidence_interval_95": {
      "lower": 0.25780063266690567,
      "upper": 0.3048280855588541,
      "width": 0.04702745289194843
    }
  },
  "by_category": {
    "defensive_security": {
      "total_samples": 150,
      "false_positives": 24,
      "fpr": 0.16,
      "specificity": 0.84,
      "confidence_interval_95": {
        "lower": 0.10993931727556672,
        "upper": 0.22704105734352203,
        "width": 0.11710174006795532
      }
    },
    "translation_quoting": {
      "total_samples": 150,
      "false_positives": 71,
      "fpr": 0.47333333333333333,
      "specificity": 0.5266666666666666,
      "confidence_interval_95": {
        "lower": 0.39509757671394596,
        "upper": 0.5529008840404923,
        "width": 0.15780330732654635
      }
    },
    "history_news_law": {
      "total_samples": 150,
      "false_positives": 7,
      "fpr": 0.04666666666666667,
      "specificity": 0.9533333333333334,
      "confidence_interval_95": {
        "lower": 0.02278625890187786,
        "upper": 0.09318757392357377,
        "width": 0.07040131502169591
      }
    },
    "filter_evaluation": {
      "total_samples": 100,
      "false_positives": 63,
      "fpr": 0.63,
      "specificity": 0.37,
      "confidence_interval_95": {
        "lower": 0.5322034757513312,
        "upper": 0.7181778743049083,
        "width": 0.1859743985535771
      }
    },
    "completely_safe": {
      "total_samples": 450,
      "false_positives": 76,
      "fpr": 0.1688888888888889,
      "specificity": 0.8311111111111111,
      "confidence_interval_95": {
        "lower": 0.13710844049223198,
        "upper": 0.20627480159046824,
        "width": 0.06916636109823626
      }
    },
    "roleplay_safe": {
      "total_samples": 100,
      "false_positives": 39,
      "fpr": 0.39,
      "specificity": 0.61,
      "confidence_interval_95": {
        "lower": 0.300167219319702,
        "upper": 0.48797163832501844,
        "width": 0.18780441900531641
      }
    },
    "meta_academic": {
      "total_samples": 150,
      "false_positives": 81,
      "fpr": 0.54,
      "specificity": 0.45999999999999996,
      "confidence_interval_95": {
        "lower": 0.46023676745464287,
        "upper": 0.6177655414136997,
        "width": 0.1575287739590568
      }
    },
    "fiction_creative": {
      "total_samples": 150,
      "false_positives": 32,
      "fpr": 0.21333333333333335,
      "specificity": 0.7866666666666666,
      "confidence_interval_95": {
        "lower": 0.15536143670182534,
        "upper": 0.28562201640838675,
        "width": 0.1302605797065614
      }
    }
  },
  "by_fil_axis": {
    "SYSTEM": 95,
    "PUBLIC": 50,
    "LIFE": 19,
    "RIGHTS": 2
  }
}